# Hi ğŸ‘‹, I'm lartpang

## ğŸ§‘â€ğŸ¤â€ğŸ§‘ Me

$$
\textbf{life} = \int_{birth}^{now} \mathbf{happy}(time) + \mathbf{sad}(time) d(time)
$$

<p align="center">
  A Python and PyTorch developer, deep-learning worker and open-source activist. I like python. Python can do anything.<br /><br />   
  <img src="https://github.com/lartpang/lartpang/assets/26847524/f040fb47-f59c-4708-aacb-7ab4e7389bc3" />  
  Created by Bing Image Creator ğŸ˜Š
</p>

- ğŸ“ I regulary write articles on [https://www.yuque.com/lart](https://www.yuque.com/lart)
- ğŸ’¬ Ask me about **Python, PyTorch** in [ISSUES](https://github.com/lartpang/lartpang/issues)
- âš¡ Fun fact **I am a boy.**

## ğŸ“ Recent Writing

<!-- writing starts -->
* [CVPR 2023 | Making Vision Transformers Efficient from A Token Sparsification View](https://blog.csdn.net/P_LarT/article/details/131226411) - Thu, 15 Jun 2023: <small>*CVPR 2023ï¼ŒåŸºäºtokenç¨€ç–åŒ–çš„transformeré«˜æ•ˆæ¨¡å‹ã€‚*</small>
* [CAT-Seg: Cost Aggregation for Open-Vocabulary Semantic Segmentation](https://blog.csdn.net/P_LarT/article/details/131083586) - Wed, 07 Jun 2023: <small>*åŸºäºå›¾åƒæ–‡æœ¬åŒ¹é…çš„cost volumeç»†åŒ–ä¸é¢„æµ‹åˆ†å‰²ã€‚*</small>
* [CVPR 2023 | EfficientViT: Memory Efficient Vision Transformer with Cascaded Group Attention](https://blog.csdn.net/P_LarT/article/details/130687567) - Mon, 15 May 2023: <small>*EfficientViTï¼Œæ¨ç†æ›´å¿«çš„ViTã€‚*</small>
* [CVPR 2023 | Reliability in Semantic Segmentation: Are We on the Right Track?](https://blog.csdn.net/P_LarT/article/details/130368801) - Tue, 25 Apr 2023: <small>*æœ€è¿‘è®¡ç®—æœºè§†è§‰ç”±äºTransformerè·å¾—äº†æ€¥é€Ÿçš„å‘å±•ï¼Œè™½ç„¶åŸŸå†…æ€§èƒ½æœ‰ç€ä¸Šå‡è¶‹åŠ¿ï¼Œä½†å¯¹é²æ£’æ€§æˆ–ä¸ç¡®å®šæ€§ä¼°è®¡ç­‰ç‰¹æ€§çš„æ¢ç´¢è¾ƒå°‘ï¼Œè¿™ä½¿äººä»¬å¯¹æ¨¡å‹å¯é æ€§æ–¹é¢çš„è¿›æ­¥æ°´å¹³äº§ç”Ÿäº†æ€€ç–‘ã€‚ç°æœ‰ä¸€äº›å·¥ä½œè™½ç„¶å¯¹æ­¤æœ‰æ‰€æ¢ç´¢ï¼Œä½†æ˜¯ä¸»è¦é›†ä¸­åœ¨åˆ†ç±»æ¨¡å‹ã€‚è¿™ä»½å·¥ä½œåœ¨è¯­ä¹‰åˆ†å‰²ä¸­å¼€å±•äº†ç›¸å…³çš„æ¢ç©¶ï¼Œæ¨ªè·¨äº†è¾ƒæ—§çš„åŸºäºResNetçš„æ¶æ„åˆ°è¾ƒæ–°çš„Transformeræ¶æ„ï¼šå‘ç°äº†å°½ç®¡æœ€è¿‘çš„æ¨¡å‹æ›´åŠ é²æ£’ï¼Œä½†åœ¨ä¸ç¡®å®šæ€§ä¼°è®¡ä¸Šæ€»ä½“å¹¶æœªæ›´å¯é ï¼›æ¢ç´¢äº†å¯ä»¥æŒ½æ•‘çš„æ–¹æ³•ï¼Œå¹¶è¡¨æ˜æå‡calibrationä¹Ÿå¯ä»¥å¸®åŠ©å…¶ä»–ä¸ç¡®å®šæ€§æŒ‡æ ‡ï¼Œå¦‚misclassificati*</small>
* [CVPR 2022 | Segment Everything Everywhere All at Once](https://blog.csdn.net/P_LarT/article/details/130298712) - Fri, 21 Apr 2023: <small>*æœ¬æ–‡åŸºäºCLIPå¼ºå¤§çš„é›¶æ ·æœ¬çš„æ–‡æœ¬ç¼–ç å’Œå›¾åƒç¼–ç èƒ½åŠ›, è®¾è®¡äº†ä¸€ä¸ªæ–°çš„ç³»ç»Ÿ, åŸºäºæµ‹è¯•æ—¶ä»»æ„çš„Promptä¿¡æ¯(ä»»æ„çš„æ–‡æœ¬æˆ–è€…å›¾åƒæç¤º), æ¥ç”Ÿæˆå›¾åƒåˆ†å‰², æ•´ä½“çš„å½¢å¼éå¸¸ç±»ä¼¼äºFew-shotçš„Segmentationå½¢å¼.*</small>
* [CVPR 2023 | Texture-guided Saliency Distilling for Unsupervised Salient Object Detection](https://blog.csdn.net/P_LarT/article/details/130269082) - Thu, 20 Apr 2023: <small>*æ— ç›‘ç£æ˜¾è‘—æ€§ç›®æ ‡æ£€æµ‹ä»»åŠ¡çš„å¸¸ç”¨ç­–ç•¥æ˜¯ä¼ªæ ‡ç­¾æ‰‹æ®µ. ä¼ªæ ‡ç­¾ä¸­ä¼šå­˜åœ¨å¤§é‡çš„å™ªå£°. å¦‚ä½•å¤„ç†å¸¦å™ªæ ‡ç­¾æ˜¯æ— ç›‘ç£æ˜¾è‘—æ€§ç›®æ ‡æ£€æµ‹ä»»åŠ¡å·¥ä½œçš„ä¸€å¤§é‡ç‚¹. ç°æœ‰æ–¹æ³•ä¸“æ³¨åˆ©ç”¨æœ‰ç€æ›´åŠ å¯é æ ‡ç­¾çš„å®¹æ˜“æ ·æœ¬, ä½†æ˜¯å¿½ç•¥äº†éš¾æ ·æœ¬ä¸­æœ‰ä»·å€¼çš„çŸ¥è¯†. è¿™ç¯‡æ–‡ç« ä¸­å…³æ³¨ä¸åŒæ—¶æŒ–æ˜éš¾æ˜“æ ·æœ¬ä¸­çš„æ˜¾è‘—æ€§çŸ¥è¯†.*</small>
* [CVPR 2023 | FreeSeg: Unified, Universal and Open-Vocabulary Image Segmentation](https://blog.csdn.net/P_LarT/article/details/130158346) - Fri, 14 Apr 2023: <small>*Open Vocabulary å­¦ä¹ èŒƒå¼å°†åˆ†å‰²ç³»ç»Ÿæ¨å¹¿åˆ°æ›´é€šç”¨çš„åº”ç”¨åœºæ™¯. ç°æœ‰çš„å®šåˆ¶åŒ–çš„è®¾è®¡èŒƒå¼å¯¼è‡´å„ç§åˆ†å‰²ä»»åŠ¡ä¹‹é—´çš„ç¢ç‰‡åŒ–, ä»è€Œé˜»ç¢äº†åˆ†å‰²æ¨¡å‹çš„ç»Ÿä¸€æ€§.
æ‰€ä»¥æœ¬æ–‡åŸºäºone-shotè®­ç»ƒçš„å½¢å¼, æå‡ºäº†ä¸€ç§ç»Ÿä¸€å‚æ•°å’Œç»“æ„çš„é€šç”¨æ¨¡å‹ç”¨äºå¤„ç† Open Vocabulary åˆ†å‰²ä»»åŠ¡.
å¹¶å¼•å…¥äº†promptæ¥ç»Ÿä¸€ä¸åŒçš„ä»»åŠ¡å’Œç±»åˆ«æ¦‚å¿µ, ä»¥é€‚åº”ä¸åŒçš„ä»»åŠ¡å’Œåœºæ™¯.*</small>
* [ECCV 2022 | MaskCLIP: Extract Free Dense Labels from CLIP](https://blog.csdn.net/P_LarT/article/details/130157634) - Fri, 14 Apr 2023: <small>*ä»¥å¾€çš„ç ”ç©¶ä¸»è¦æ˜¯åˆ©ç”¨CLIPç‰¹å¾ä½œä¸ºä¸€ç§å…¨å±€å›¾åƒè¡¨ç¤ºï¼Œæœ¬æ–‡ä¸»è¦æ¢ç´¢é¢„è®­ç»ƒçš„CLIPæ¨¡å‹å¯¹äºåƒç´ çº§é¢„æµ‹ä»»åŠ¡çš„æ½œåœ¨ä¼˜åŠ¿ã€‚*</small>
* [CVPR | Generative Semantic Segmentation](https://blog.csdn.net/P_LarT/article/details/129988887) - Thu, 06 Apr 2023: <small>*ä½¿ç”¨ç”Ÿæˆæ–¹æ³•å»ºç«‹çš„å›¾åƒåˆ†å‰²æ¨¡å‹*</small>
* [windows ä¸Šç¼–è¯‘ cpu ç‰ˆæœ¬çš„ ncnn](https://blog.csdn.net/P_LarT/article/details/128956760) - Thu, 09 Feb 2023: <small>*windows ncnn cpu*</small>
<!-- writing ends -->

View the archives @ [csdn@p_lart](https://blog.csdn.net/p_lart).

## ğŸ“½ï¸ Some Projects

**PyTorch.**
* [**PyTorchTricks**](https://github.com/lartpang/PyTorchTricks), Some tricks of pytorchâ€¦ :star:

**SOD.**
* **New:rocket::rocket::rocket:** [**MethodsCmp**](https://github.com/lartpang/MethodsCmp), A simple toolkit for counting the FLOPs/MACs, Parameters and FPS of the model.
* **Practical:wrench:** [**PySODEvalToolkit**](https://github.com/lartpang/PySODEvalToolkit), A Python-based salient object detection and video object segmentation evaluation toolbox.
* **Practical:wrench:** [**PySODMetrics**](https://github.com/lartpang/PySODMetrics), A simple and efficient implementation of SOD metrcis.
* [**PyLoss**](https://github.com/lartpang/PyLoss), Some loss functions for deeplearning.
* [**OpticalFlowBasedVOS**](https://github.com/lartpang/OpticalFlowBasedVOS), A simple and efficient codebase for the optical flow based video object segmentation.
* [**CoSaliencyProj**](https://github.com/lartpang/CoSaliencyProj), A project for co-saliency detection. Some codes are borrowed from ICNet. Thanks to ICNet Intra-saliency Correlation Network for Co-Saliency Detection (NIPS2020)~

**Usefull tools for your deeplearning project.**
* [**RunIt**](https://github.com/lartpang/RunIt), A simple program scheduler for your code on different devices.
* [**RegisterIt**](https://github.com/lartpang/RegisterIt), Register it: A more flexible register for the DeepLearning project.
* [**MSSIM.pytorch**](https://github.com/lartpang/MSSIM.pytorch), A better pytorch-based implementation for the mean structural similarity. Differentiable simpler SSIM and MS-SSIM.

**Other usefull tools.**
* [**YuQueTools**](https://github.com/lartpang/YuQueTools), A simple tool to download your own articles from yuque.
* [**ManageMyAttachments**](https://github.com/lartpang/ManageMyAttachments), Manage the attachments of your own obsidian vault.

<p align="center">Generated by <a href="https://rahuldkjain.github.io/gh-profile-readme-generator/" alt="generator">Readme Generator</a></p>
