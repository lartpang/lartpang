# Hi ğŸ‘‹, I'm lartpang

## ğŸ§‘â€ğŸ¤â€ğŸ§‘ Me

$$
\textbf{life} = \int_{birth}^{now} \mathbf{happy}(time) + \mathbf{sad}(time) d(time)
$$

<p align="center">A Python and PyTorch developer, deep-learning worker and open-source activist. I like python. Python can do anything.</p>

- ğŸ“ I regulary write articles on [https://www.yuque.com/lart](https://www.yuque.com/lart)
- ğŸ’¬ Ask me about **Python, PyTorch** in [ISSUES](https://github.com/lartpang/lartpang/issues)
- âš¡ Fun fact **I am a boy.**

## ğŸ“ Recent Writing

<!-- writing starts -->
* [CVPR 2022 |NeW CRFs: Neural Window Fully-connected CRFs for Monocular Depth Estimation](https://blog.csdn.net/P_LarT/article/details/127124910) - Fri, 30 Sep 2022: <small>*è¿™ç¯‡æ–‡ç« å°†å…¨å±€å…¨è¿æ¥CRFä½¿ç”¨Attentionè¿›è¡Œäº†æ”¹é€ ï¼Œå¹¶ä½¿ç”¨äº†åŸºäºçª—åç§»çš„è®¡ç®—è¿‡ç¨‹å®ç°äº†æ›´ä½çš„è®¡ç®—é‡ã€‚æå‡ºçš„ç»“æ„è¢«ç”¨äºå•ç›®æ·±åº¦ä¼°è®¡ä»»åŠ¡æ¨¡å‹çš„æ„å»ºä¸­ã€‚*</small>
* [ICCV 2021 Oral | CoaT: Co-Scale Conv-Attentional Image Transformers](https://blog.csdn.net/P_LarT/article/details/127023702) - Sat, 24 Sep 2022: <small>*è®¾è®¡äº†ä¸€ç§ç®€åŒ–çš„çº¿æ€§æ³¨æ„åŠ›æœºåˆ¶ï¼Œå¹¶å¼•å…¥äº†å·ç§¯ç›¸å¯¹ä½ç½®ç¼–ç ã€‚åŸºäºè¿™äº›æ„å»ºäº†ä¸€ä¸ªåŒ…å«å¤šå°ºåº¦ç‰¹å¾äº¤äº’çš„æ¶æ„ã€‚*</small>
* [CVPR2022 | MPViT: Multi-Path Vision Transformer for Dense Prediction](https://blog.csdn.net/P_LarT/article/details/126989548) - Thu, 22 Sep 2022: <small>*æœ¬æ–‡é‡ç‚¹æ¢ç©¶Transformerä¸­çš„multi-scale patch embeddingå’Œmulti-path structure schemeçš„è®¾è®¡ã€‚*</small>
* [OpenCV DNNæ¨¡å—å¸¸ç”¨æ“ä½œ](https://blog.csdn.net/P_LarT/article/details/126961138) - Tue, 20 Sep 2022: <small>*åœ¨å®é™…åˆ©ç”¨opencvæä¾›çš„dnnæ¨¡å—éƒ¨ç½²onnxæ ¼å¼çš„æ¨¡å‹çš„æ—¶å€™ï¼Œä¸€äº›pythonç«¯åˆ©ç”¨numpyå¯ä»¥ç®€å•è½»æ˜“å®ç°çš„æ“ä½œï¼Œåœ¨C++ç«¯å°±å¾—ä»”ç»†è€ƒè™‘ä¸‹å®ç°çš„ç­–ç•¥äº†ã€‚å› ä¸ºå¤§å¤šæ•°å¹¶æ²¡æœ‰éå¸¸ç®€å•æ–¹ä¾¿åœ°ä½¿ç”¨å½¢å¼ï¼Œç”šè‡³å¯èƒ½éœ€è¦è‡ªå·±å»å®ç°ã€‚è¿™é‡Œåšä¸€ä¸ªè®°å½•ã€‚*</small>
* [CVPR 2022 Oral | MAXIM: Multi-Axis MLP for Image Processing](https://blog.csdn.net/P_LarT/article/details/126931492) - Mon, 19 Sep 2022: <small>*è¿™æ˜¯ä¸€ç¯‡åœ¨åº•å±‚è§†è§‰ä»»åŠ¡ä¸Šæ„å»ºæ›´æœ‰æ•ˆçš„å±€éƒ¨+å…¨å±€äº¤äº’ç­–ç•¥çš„æ–‡ç« ï¼Œå†å¤šä¸ªä»»åŠ¡ä¸Šå®ç°äº†è‰¯å¥½çš„æ•ˆæœã€‚*</small>
* [ECCV 2022 | MaxViT: Multi-Axis Vision Transformer](https://blog.csdn.net/P_LarT/article/details/126903713) - Sat, 17 Sep 2022: <small>*æœ¬æ–‡æ˜¯é’ˆå¯¹Attentionæ“ä½œçš„ä¸€ç§æ”¹è¿›ã€‚æ€è·¯ä¸Šæ¥è¯´ä¹‹å‰çš„å·ç§¯æ–¹æ³•ä¸­å·²ç»ä½¿ç”¨è¿‡ç±»ä¼¼çš„ç­–ç•¥ï¼Œä½†æ˜¯ä½œè€…ä»¬å°†è¿™ç§æ€è·¯ç”¨åœ¨Attentionä¸­ï¼Œä¹Ÿå±•ç°å‡ºäº†è‰¯å¥½çš„æ•ˆæœã€‚æå‡ºçš„ç»“æ„Multi-Axis Attentionæœ‰æ•ˆæ”¹å–„äº†åŸå§‹Attentionåœ¨å®é™…åº”ç”¨ä¸­æ‰€æ¬ ç¼ºçš„å¯æ”¾ç¼©æ€§ï¼Œèƒ½å¤Ÿæ›´æœ‰æ•ˆçš„å¤„ç†é«˜åˆ†è¾¨ç‡ç‰¹å¾ã€‚å…·ä½“è€Œè¨€ï¼Œå°±æ˜¯é€šè¿‡å®Œå…¨å€ŸåŠ©å±€éƒ¨æ³¨æ„åŠ›å®ç°äº†å±€éƒ¨äº¤äº’å’Œå…¨å±€äº¤äº’çš„å½¢å¼ï¼ˆå…¨å±€äº¤äº’çš„å®ç°æ€æƒ³å…¶å®å€¼å¾—å€Ÿé‰´ï¼‰ï¼Œåœ¨æœ‰æ•ˆé™ä½è®¡ç®—å¤æ‚åº¦çš„æƒ…å†µä¸‹ï¼Œä»ç„¶è·å¾—äº†è‰¯å¥½çš„è¡¨ç°ã€‚*</small>
* [Arxiv 2209 | Switchable Self-attention Module](https://blog.csdn.net/P_LarT/article/details/126896049) - Fri, 16 Sep 2022: <small>*è¿™ç¯‡æ–‡ç« è®¾è®¡äº†ä¸€ç§å¯åˆ‡æ¢å¼çš„æ³¨æ„åŠ›æ¨¡å—ï¼ˆé¢˜ç›®ä¸­æ˜¯self-attentionï¼Œä½†æ˜¯å®é™…æ¨¡å—è®¾è®¡ç”¨çš„è¿˜æ˜¯åŸå§‹çš„é€šé“æ³¨æ„åŠ›ï¼‰ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œå®éªŒæ€§çš„å‘ç°å¯¹äºä¸åŒçš„ç½‘ç»œå±‚å’Œä¸åŒçš„åœºæ™¯ä¸­ï¼Œå¯¹äºæ³¨æ„åŠ›æ¨¡å—è€Œè¨€ï¼Œé€‰æ‹©ä½¿ç”¨åˆé€‚çš„æ¿€åŠ±æ“ä½œæ˜¯æ›´æœ‰å¿…è¦çš„ã€‚*</small>
* [ECCV 2022 | Lightweight Attentional Feature Fusion: A New Baseline for Text-to-Video Retrieval](https://blog.csdn.net/P_LarT/article/details/126878555) - Thu, 15 Sep 2022: <small>*æœ¬æ–‡ä¸»è¦è®¨è®ºäº†æ–‡æœ¬æ£€ç´¢è§†é¢‘ä»»åŠ¡ä¸­çš„ç‰¹å¾èåˆé—®é¢˜ã€‚æå‡ºäº†ä¸€ç§åŸºäºè½»é‡ä½†æ˜¯æœ‰æ•ˆçš„ç‰¹å¾èåˆæ¨¡å—LAFFæ„å»ºçš„è·¨æ¨¡æ€åŒç«¯èåˆæ¶æ„ã€‚*</small>
* [ä½¿ç”¨æ·±åº¦å›¾åƒå®ç°ç…§ç‰‡è™šåŒ–æ•ˆæœ](https://blog.csdn.net/P_LarT/article/details/126606557) - Tue, 30 Aug 2022: <small>*æœ¬æ–‡è®¨è®ºäº†å¦‚ä½•é€šè¿‡RGB-Då›¾åƒå¯¹å®ç°ç…§ç‰‡è™šåŒ–ã€‚*</small>
* [ä»äºŒå€¼ Mask è·å–å¤–æ¥çŸ©å½¢åæ ‡](https://blog.csdn.net/P_LarT/article/details/126604438) - Tue, 30 Aug 2022: <small>*åœ¨æ•°å­—å›¾åƒå¤„ç†ä¸­ï¼Œæˆ‘ä»¬æœ‰æ—¶å€™ä¼šéœ€è¦è®¡ç®—äºŒå€¼maskå¯¹åº”çš„å¤–æ¥çŸ©å½¢ã€‚æœ¬æ–‡é’ˆå¯¹è¿™ä¸€é—®é¢˜ç»™å‡ºäº†å‡ ç§æ–¹ä¾¿çš„ç­–ç•¥ã€‚*</small>
<!-- writing ends -->

View the archives @ [csdn@p_lart](https://blog.csdn.net/p_lart).

## ğŸ“½ï¸ Some Projects

**PyTorch.**
* [**PyTorchTricks**](https://github.com/lartpang/PyTorchTricks), Some tricks of pytorchâ€¦ :star:

**SOD.**
* **New:rocket::rocket::rocket:** [**MethodsCmp**](https://github.com/lartpang/MethodsCmp), A simple toolkit for counting the FLOPs/MACs, Parameters and FPS of the model.
* **Practical:wrench:** [**PySODEvalToolkit**](https://github.com/lartpang/PySODEvalToolkit), A Python-based salient object detection and video object segmentation evaluation toolbox.
* **Practical:wrench:** [**PySODMetrics**](https://github.com/lartpang/PySODMetrics), A simple and efficient implementation of SOD metrcis.
* [**PyLoss**](https://github.com/lartpang/PyLoss), Some loss functions for deeplearning.
* [**OpticalFlowBasedVOS**](https://github.com/lartpang/OpticalFlowBasedVOS), A simple and efficient codebase for the optical flow based video object segmentation.
* [**CoSaliencyProj**](https://github.com/lartpang/CoSaliencyProj), A project for co-saliency detection. Some codes are borrowed from ICNet. Thanks to ICNet Intra-saliency Correlation Network for Co-Saliency Detection (NIPS2020)~

**Usefull tools for your deeplearning project.**
* [**RunIt**](https://github.com/lartpang/RunIt), A simple program scheduler for your code on different devices.
* [**RegisterIt**](https://github.com/lartpang/RegisterIt), Register it: A more flexible register for the DeepLearning project.
* [**MSSIM.pytorch**](https://github.com/lartpang/MSSIM.pytorch), A better pytorch-based implementation for the mean structural similarity. Differentiable simpler SSIM and MS-SSIM.

<p align="center"><img src="https://komarev.com/ghpvc/?username=lartpang" alt="lartpang" /></p>
<p align="center">Generated by <a href="https://rahuldkjain.github.io/gh-profile-readme-generator/" alt="generator">Readme Generator</a></p>
