# Hi ğŸ‘‹, I'm lartpang

## ğŸ§‘â€ğŸ¤â€ğŸ§‘ Me

$$
\textbf{life} = \int_{birth}^{now} \mathbf{happy}(time) + \mathbf{sad}(time) d(time)
$$

<p align="center">A Python and PyTorch developer, deep-learning worker and open-source activist. I like python. Python can do anything.</p>

- ğŸ“ I regulary write articles on [https://www.yuque.com/lart](https://www.yuque.com/lart)
- ğŸ’¬ Ask me about **Python, PyTorch** in [ISSUES](https://github.com/lartpang/lartpang/issues)
- âš¡ Fun fact **I am a boy.**

## ğŸ“ Recent Writing

<!-- writing starts -->
* [ECCV 2022 | MaxViT: Multi-Axis Vision Transformer](https://blog.csdn.net/P_LarT/article/details/126903713) - Sat, 17 Sep 2022: <small>*æœ¬æ–‡æ˜¯é’ˆå¯¹Attentionæ“ä½œçš„ä¸€ç§æ”¹è¿›ã€‚æ€è·¯ä¸Šæ¥è¯´ä¹‹å‰çš„å·ç§¯æ–¹æ³•ä¸­å·²ç»ä½¿ç”¨è¿‡ç±»ä¼¼çš„ç­–ç•¥ï¼Œä½†æ˜¯ä½œè€…ä»¬å°†è¿™ç§æ€è·¯ç”¨åœ¨Attentionä¸­ï¼Œä¹Ÿå±•ç°å‡ºäº†è‰¯å¥½çš„æ•ˆæœã€‚

æå‡ºçš„ç»“æ„Multi-Axis Attentionæœ‰æ•ˆæ”¹å–„äº†åŸå§‹Attentionåœ¨å®é™…åº”ç”¨ä¸­æ‰€æ¬ ç¼ºçš„å¯æ”¾ç¼©æ€§ï¼Œèƒ½å¤Ÿæ›´æœ‰æ•ˆçš„å¤„ç†é«˜åˆ†è¾¨ç‡ç‰¹å¾ã€‚å…·ä½“è€Œè¨€ï¼Œå°±æ˜¯é€šè¿‡å®Œå…¨å€ŸåŠ©å±€éƒ¨æ³¨æ„åŠ›å®ç°äº†å±€éƒ¨äº¤äº’å’Œå…¨å±€äº¤äº’çš„å½¢å¼ï¼ˆå…¨å±€äº¤äº’çš„å®ç°æ€æƒ³å…¶å®å€¼å¾—å€Ÿé‰´ï¼‰ï¼Œåœ¨æœ‰æ•ˆé™ä½è®¡ç®—å¤æ‚åº¦çš„æƒ…å†µä¸‹ï¼Œä»ç„¶è·å¾—äº†è‰¯å¥½çš„è¡¨ç°ã€‚*</small>
* [Arxiv 2209 | Switchable Self-attention Module](https://blog.csdn.net/P_LarT/article/details/126896049) - Fri, 16 Sep 2022: <small>*è¿™ç¯‡æ–‡ç« è®¾è®¡äº†ä¸€ç§å¯åˆ‡æ¢å¼çš„æ³¨æ„åŠ›æ¨¡å—ï¼ˆé¢˜ç›®ä¸­æ˜¯self-attentionï¼Œä½†æ˜¯å®é™…æ¨¡å—è®¾è®¡ç”¨çš„è¿˜æ˜¯åŸå§‹çš„é€šé“æ³¨æ„åŠ›ï¼‰ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œå®éªŒæ€§çš„å‘ç°å¯¹äºä¸åŒçš„ç½‘ç»œå±‚å’Œä¸åŒçš„åœºæ™¯ä¸­ï¼Œå¯¹äºæ³¨æ„åŠ›æ¨¡å—è€Œè¨€ï¼Œé€‰æ‹©ä½¿ç”¨åˆé€‚çš„æ¿€åŠ±æ“ä½œæ˜¯æ›´æœ‰å¿…è¦çš„ã€‚*</small>
* [ECCV 2022 | Lightweight Attentional Feature Fusion: A New Baseline for Text-to-Video Retrieval](https://blog.csdn.net/P_LarT/article/details/126878555) - Thu, 15 Sep 2022: <small>*æœ¬æ–‡ä¸»è¦è®¨è®ºäº†æ–‡æœ¬æ£€ç´¢è§†é¢‘ä»»åŠ¡ä¸­çš„ç‰¹å¾èåˆé—®é¢˜ã€‚æå‡ºäº†ä¸€ç§åŸºäºè½»é‡ä½†æ˜¯æœ‰æ•ˆçš„ç‰¹å¾èåˆæ¨¡å—LAFFæ„å»ºçš„è·¨æ¨¡æ€åŒç«¯èåˆæ¶æ„ã€‚*</small>
* [ä½¿ç”¨æ·±åº¦å›¾åƒå®ç°ç…§ç‰‡è™šåŒ–æ•ˆæœ](https://blog.csdn.net/P_LarT/article/details/126606557) - Tue, 30 Aug 2022: <small>*æœ¬æ–‡è®¨è®ºäº†å¦‚ä½•é€šè¿‡RGB-Då›¾åƒå¯¹å®ç°ç…§ç‰‡è™šåŒ–ã€‚*</small>
* [ä»äºŒå€¼ Mask è·å–å¤–æ¥çŸ©å½¢åæ ‡](https://blog.csdn.net/P_LarT/article/details/126604438) - Tue, 30 Aug 2022: <small>*åœ¨æ•°å­—å›¾åƒå¤„ç†ä¸­ï¼Œæˆ‘ä»¬æœ‰æ—¶å€™ä¼šéœ€è¦è®¡ç®—äºŒå€¼maskå¯¹åº”çš„å¤–æ¥çŸ©å½¢ã€‚æœ¬æ–‡é’ˆå¯¹è¿™ä¸€é—®é¢˜ç»™å‡ºäº†å‡ ç§æ–¹ä¾¿çš„ç­–ç•¥ã€‚*</small>
* [å¦‚ä½•è®¡ç®—è´¨å¿ƒ](https://blog.csdn.net/P_LarT/article/details/126474206) - Mon, 22 Aug 2022: <small>*æœ¬æ–‡ä»‹ç»äº†è´¨å¿ƒçš„æ¦‚å¿µï¼Œä»¥åŠåŸºäºNumpyã€Scipyã€OpenCVç­‰å·¥å…·çš„å¤šç§å®ç°æ–¹å¼ã€‚*</small>
* [Arxiv 2207 | HorNet: Efficient High-Order Spatial Interactions with Recursive Gated Convolutions](https://blog.csdn.net/P_LarT/article/details/126416277) - Fri, 19 Aug 2022: <small>*è¿™ç¯‡æ–‡ç« æ—¨åœ¨ä½¿ç”¨å·ç§¯ç»“æ„è®¾è®¡ä¸€ç§æ›´åŠ æœ‰æ•ˆçš„ç©ºé—´äº¤äº’æ¨¡å—ã€‚ä½œè€…ä»¬é€šè¿‡é€’å½’é—¨æ§ç­–ç•¥è®¾è®¡äº†é€’å½’é—¨æ§å·ç§¯æ“ä½œï¼Œä»è€Œåœ¨ç‰¹å¾å†…éƒ¨æ„å»ºäº†æ›´é«˜é˜¶çš„ç©ºé—´äº¤äº’è¿‡ç¨‹ã€‚è¿™ç§ç»“æ„å¯ä»¥ä½œè€…ä¸ºä¸€ç§å³æ’å³ç”¨çš„æ¨¡å—æ¥æå‡è§†è§‰Transformeræˆ–è€…å·ç§¯æ¨¡å‹ã€‚é™¤äº†æ„å»ºbackboneï¼Œä¹Ÿå¯ä»¥ç”¨äºè§£ç å™¨æ¥æå‡å¯†é›†é¢„æµ‹ä»»åŠ¡çš„æ€§èƒ½ã€‚...*</small>
* [Arxiv 2206 | Global Context Vision Transformers](https://blog.csdn.net/P_LarT/article/details/126409460) - Thu, 18 Aug 2022: <small>*æœ¬æ–‡çš„ç›®çš„ä¸»è¦åœ¨äºæ”¹è¿›è‡ªæ³¨æ„åŠ›è®¡ç®—çš„é«˜æ˜‚è®¡ç®—æˆæœ¬ã€‚æ‰€ä»¥åŸºäºå±€éƒ¨è‡ªæ³¨æ„åŠ›çš„å½¢å¼è¿›è¡Œäº†æ‰©å±•ï¼Œå®ç°äº†ä¸€ç§æ›´åŠ é«˜æ•ˆçš„å…¨å±€æ³¨æ„åŠ›å½¢å¼ï¼Œè€Œå…å»äº†Swiné‚£æ ·çš„åˆ’çª—æ“ä½œï¼ˆåˆ’çª—æ“ä½œéœ€è¦è¿›è¡Œpaddingå’Œmaskï¼Œä»¥åŠåˆ’çª—ä»…ä»…ä¼šè¦†ç›–ä¸åŒå±€éƒ¨åŒºåŸŸçš„éƒ¨åˆ†å†…å®¹ï¼‰æˆ–è€…å…¶ä»–æ›´ä¸ºå¤æ‚çš„ä¾‹å¦‚token unfoldingå’Œrollingæ“ä½œï¼Œç”šè‡³æ˜¯å¯¹äºkeyå’Œvalueçš„é¢å¤–è®¡ç®—ã€‚......*</small>
* [Arxiv 2207 | LightViT: Towards Light-Weight Convolution-Free Vision Transformers](https://blog.csdn.net/P_LarT/article/details/126301936) - Fri, 12 Aug 2022: <small>*æœ¬æ–‡æ—¨åœ¨æ”¹è¿›è½»é‡è§†è§‰Transformeræ¨¡å‹çš„è®¾è®¡ã€‚*</small>
* [å°å¿ƒä½ çš„å­—å…¸å’Œæ ·æ¿ä»£ç ](https://blog.csdn.net/P_LarT/article/details/126070605) - Sat, 30 Jul 2022: <small>*ç¼–ç é”™è¯¯åæ€*</small>
<!-- writing ends -->

View the archives @ [csdn@p_lart](https://blog.csdn.net/p_lart).

## ğŸ“½ï¸ Some Projects

**PyTorch.**
* [**PyTorchTricks**](https://github.com/lartpang/PyTorchTricks), Some tricks of pytorchâ€¦ :star:

**SOD.**
* **New:rocket::rocket::rocket:** [**MethodsCmp**](https://github.com/lartpang/MethodsCmp), A simple toolkit for counting the FLOPs/MACs, Parameters and FPS of the model.
* **Practical:wrench:** [**PySODEvalToolkit**](https://github.com/lartpang/PySODEvalToolkit), A Python-based salient object detection and video object segmentation evaluation toolbox.
* **Practical:wrench:** [**PySODMetrics**](https://github.com/lartpang/PySODMetrics), A simple and efficient implementation of SOD metrcis.
* [**PyLoss**](https://github.com/lartpang/PyLoss), Some loss functions for deeplearning.
* [**OpticalFlowBasedVOS**](https://github.com/lartpang/OpticalFlowBasedVOS), A simple and efficient codebase for the optical flow based video object segmentation.
* [**CoSaliencyProj**](https://github.com/lartpang/CoSaliencyProj), A project for co-saliency detection. Some codes are borrowed from ICNet. Thanks to ICNet Intra-saliency Correlation Network for Co-Saliency Detection (NIPS2020)~

**Usefull tools for your deeplearning project.**
* [**RunIt**](https://github.com/lartpang/RunIt), A simple program scheduler for your code on different devices.
* [**RegisterIt**](https://github.com/lartpang/RegisterIt), Register it: A more flexible register for the DeepLearning project.
* [**MSSIM.pytorch**](https://github.com/lartpang/MSSIM.pytorch), A better pytorch-based implementation for the mean structural similarity. Differentiable simpler SSIM and MS-SSIM.

<p align="center"><img src="https://komarev.com/ghpvc/?username=lartpang" alt="lartpang" /></p>
<p align="center">Generated by <a href="https://rahuldkjain.github.io/gh-profile-readme-generator/" alt="generator">Readme Generator</a></p>
